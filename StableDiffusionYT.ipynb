{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a28874171a884ce79ecf7a65c28f7e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f050c088c9a84112b612e46941a2882d",
              "IPY_MODEL_367af58071f345dca7214e640ddab179",
              "IPY_MODEL_f56b12a3c3874576b5a78cfb33ad0fac",
              "IPY_MODEL_33012012af534d38867b2958ad2550f3",
              "IPY_MODEL_66e048a69357473c843e85ff4305e817"
            ],
            "layout": "IPY_MODEL_afe7aff0b47b44bf88caba6a4c0cae06"
          }
        },
        "f050c088c9a84112b612e46941a2882d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88badd9869974192a8f9c3e313d476e1",
            "placeholder": "​",
            "style": "IPY_MODEL_13dee15391b348e0bbc001b0b6955d9c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "367af58071f345dca7214e640ddab179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_024a7736863545f1aa2b79f94dd62e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_9bfac86bd35a40cc8e3ebd67550fc26d",
            "value": ""
          }
        },
        "f56b12a3c3874576b5a78cfb33ad0fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_84f488c580ce4794ae90772a99eac26e",
            "style": "IPY_MODEL_d65ff5a7db0a418e9b792c94b9ec3792",
            "value": true
          }
        },
        "33012012af534d38867b2958ad2550f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d05279a2bd31496cac1223f9728d3c25",
            "style": "IPY_MODEL_71d9ccc8d0c648fc8cf97888ece8767f",
            "tooltip": ""
          }
        },
        "66e048a69357473c843e85ff4305e817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37d1245c4c9481e82c237cb7aad89d0",
            "placeholder": "​",
            "style": "IPY_MODEL_bd44394e8881442485cfa6df1925036b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "afe7aff0b47b44bf88caba6a4c0cae06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "88badd9869974192a8f9c3e313d476e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13dee15391b348e0bbc001b0b6955d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024a7736863545f1aa2b79f94dd62e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bfac86bd35a40cc8e3ebd67550fc26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f488c580ce4794ae90772a99eac26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65ff5a7db0a418e9b792c94b9ec3792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d05279a2bd31496cac1223f9728d3c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d9ccc8d0c648fc8cf97888ece8767f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d37d1245c4c9481e82c237cb7aad89d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd44394e8881442485cfa6df1925036b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyasi7/Priyasi7/blob/main/StableDiffusionYT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4QuVPOmSFhRj",
        "outputId": "16d1ec56-7437-4366-88fb-550ed2d71edb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.2.4\n",
            "  Downloading diffusers-0.2.4-py3-none-any.whl (112 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/113.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (2.1.0+cu121)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.2.4) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers==0.2.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers==0.2.4) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers==0.2.4) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers==0.2.4) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.2.4) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.2.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.2.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.2.4) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->diffusers==0.2.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->diffusers==0.2.4) (1.3.0)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.2.4\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.3\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7) (3.0.10)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8,>=7)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8,>=7) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (3.1.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8,>=7) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8,>=7) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (4.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7) (2.21)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from torch.nn import functional as F\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n",
        "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "from huggingface_hub import notebook_login\n",
        "from google.colab import output\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "a28874171a884ce79ecf7a65c28f7e6a",
            "f050c088c9a84112b612e46941a2882d",
            "367af58071f345dca7214e640ddab179",
            "f56b12a3c3874576b5a78cfb33ad0fac",
            "33012012af534d38867b2958ad2550f3",
            "66e048a69357473c843e85ff4305e817",
            "afe7aff0b47b44bf88caba6a4c0cae06",
            "88badd9869974192a8f9c3e313d476e1",
            "13dee15391b348e0bbc001b0b6955d9c",
            "024a7736863545f1aa2b79f94dd62e9c",
            "9bfac86bd35a40cc8e3ebd67550fc26d",
            "84f488c580ce4794ae90772a99eac26e",
            "d65ff5a7db0a418e9b792c94b9ec3792",
            "d05279a2bd31496cac1223f9728d3c25",
            "71d9ccc8d0c648fc8cf97888ece8767f",
            "d37d1245c4c9481e82c237cb7aad89d0",
            "bd44394e8881442485cfa6df1925036b"
          ]
        },
        "id": "Mb-u1yDAJ23R",
        "outputId": "5fd8eb02-8451-4f64-f438-a780b814afba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a28874171a884ce79ecf7a65c28f7e6a"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure you're logged in with `huggingface-cli login`\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'CompVis/stable-diffusion-v1-4', revision='fp16',\n",
        "    torch_dtype=torch.float16, use_auth_token=True)\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "id": "rJ50eLT9KJnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Cute shiba inu dog'\n",
        "with autocast(device):\n",
        "  image = pipe(prompt)['sample'][0]\n",
        "image"
      ],
      "metadata": {
        "id": "f-R85DLFKe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "oEXRVPQRLXDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images = 3\n",
        "prompts = ['Planet scale halo of water in space digital art'] * n_images\n",
        "with autocast(device):\n",
        "  images = pipe(prompts, num_inference_steps=50)['sample']\n",
        "image_grid(images, rows=1, cols=3)"
      ],
      "metadata": {
        "id": "fkx1cqI8LbLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ba9GNvISOatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "koFLQtrhOdLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the autoencoder model which will be used to decode the latents into image space.\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    'CompVis/stable-diffusion-v1-4', subfolder='vae', use_auth_token=True)\n",
        "vae = vae.to(device)\n",
        "\n",
        "# 2. Load the tokenizer and text encoder to tokenize and encode the text.\n",
        "tokenizer = CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14')\n",
        "text_encoder = CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\n",
        "text_encoder = text_encoder.to(device)\n",
        "\n",
        "# 3. The UNet model for generating the latents.\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    'CompVis/stable-diffusion-v1-4', subfolder='unet', use_auth_token=True)\n",
        "unet = unet.to(device)\n",
        "\n",
        "# 4. Create a scheduler for inference\n",
        "scheduler = LMSDiscreteScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012,\n",
        "    beta_schedule='scaled_linear', num_train_timesteps=1000)"
      ],
      "metadata": {
        "id": "zvSYM_B1OdPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embeds(prompt):\n",
        "  # Tokenize text and get embeddings\n",
        "  text_input = tokenizer(\n",
        "      prompt, padding='max_length', max_length=tokenizer.model_max_length,\n",
        "      truncation=True, return_tensors='pt')\n",
        "  with torch.no_grad():\n",
        "    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]\n",
        "\n",
        "  # Do the same for unconditional embeddings\n",
        "  uncond_input = tokenizer(\n",
        "      [''] * len(prompt), padding='max_length',\n",
        "      max_length=tokenizer.model_max_length, return_tensors='pt')\n",
        "  with torch.no_grad():\n",
        "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]\n",
        "\n",
        "  # Cat for final embeddings\n",
        "  text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "  return text_embeddings\n",
        "\n",
        "# test_embeds = get_text_embeds(['cute dog'])\n",
        "# print(test_embeds)\n",
        "# print(test_embeds.shape)"
      ],
      "metadata": {
        "id": "pPG1gZlWO2HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_latents(text_embeddings, height=512, width=512,\n",
        "                    num_inference_steps=50, guidance_scale=7.5, latents=None):\n",
        "  if latents is None:\n",
        "    latents = torch.randn((text_embeddings.shape[0] // 2, unet.in_channels, \\\n",
        "                           height // 8, width // 8))\n",
        "  latents = latents.to(device)\n",
        "\n",
        "  scheduler.set_timesteps(num_inference_steps)\n",
        "  latents = latents * scheduler.sigmas[0]\n",
        "\n",
        "  with autocast('cuda'):\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "      # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "      latent_model_input = torch.cat([latents] * 2)\n",
        "      sigma = scheduler.sigmas[i]\n",
        "      latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "      # predict the noise residual\n",
        "      with torch.no_grad():\n",
        "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)['sample']\n",
        "\n",
        "      # perform guidance\n",
        "      noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "      noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "      # compute the previous noisy sample x_t -> x_t-1\n",
        "      latents = scheduler.step(noise_pred, i, latents)['prev_sample']\n",
        "\n",
        "  return latents\n",
        "\n",
        "# test_latents = produce_latents(test_embeds)\n",
        "# print(test_latents)\n",
        "# print(test_latents.shape)"
      ],
      "metadata": {
        "id": "LRz09rdqQVEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_img_latents(latents):\n",
        "  latents = 1 / 0.18215 * latents\n",
        "\n",
        "  with torch.no_grad():\n",
        "    imgs = vae.decode(latents)\n",
        "\n",
        "  imgs = (imgs / 2 + 0.5).clamp(0, 1)\n",
        "  imgs = imgs.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "  imgs = (imgs * 255).round().astype('uint8')\n",
        "  pil_images = [Image.fromarray(image) for image in imgs]\n",
        "  return pil_images\n",
        "\n",
        "# imgs = decode_img_latents(test_latents)\n",
        "# imgs[0]"
      ],
      "metadata": {
        "id": "KbmrA5ocR42W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_to_img(prompts, height=512, width=512, num_inference_steps=50,\n",
        "                  guidance_scale=7.5, latents=None):\n",
        "  if isinstance(prompts, str):\n",
        "    prompts = [prompts]\n",
        "\n",
        "  # Prompts -> text embeds\n",
        "  text_embeds = get_text_embeds(prompts)\n",
        "\n",
        "  # Text embeds -> img latents\n",
        "  latents = produce_latents(\n",
        "      text_embeds, height=height, width=width, latents=latents,\n",
        "      num_inference_steps=num_inference_steps, guidance_scale=guidance_scale)\n",
        "\n",
        "  # Img latents -> imgs\n",
        "  imgs = decode_img_latents(latents)\n",
        "\n",
        "  return imgs"
      ],
      "metadata": {
        "id": "OnALITW_SO6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_to_img('Super cool anime character', 512, 512, 20)[0]"
      ],
      "metadata": {
        "id": "9s8QKfjeSV-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a Video"
      ],
      "metadata": {
        "id": "9ChuI2Q5SnSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_latents(text_embeddings, height=512, width=512,\n",
        "                    num_inference_steps=50, guidance_scale=7.5, latents=None,\n",
        "                    return_all_latents=False):\n",
        "  if latents is None:\n",
        "    latents = torch.randn((text_embeddings.shape[0] // 2, unet.in_channels, \\\n",
        "                           height // 8, width // 8))\n",
        "  latents = latents.to(device)\n",
        "\n",
        "  scheduler.set_timesteps(num_inference_steps)\n",
        "  latents = latents * scheduler.sigmas[0]\n",
        "\n",
        "  latent_hist = [latents]\n",
        "  with autocast('cuda'):\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "      # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "      latent_model_input = torch.cat([latents] * 2)\n",
        "      sigma = scheduler.sigmas[i]\n",
        "      latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "      # predict the noise residual\n",
        "      with torch.no_grad():\n",
        "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)['sample']\n",
        "\n",
        "      # perform guidance\n",
        "      noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "      noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "      # compute the previous noisy sample x_t -> x_t-1\n",
        "      latents = scheduler.step(noise_pred, i, latents)['prev_sample']\n",
        "      latent_hist.append(latents)\n",
        "\n",
        "  if not return_all_latents:\n",
        "    return latents\n",
        "\n",
        "  all_latents = torch.cat(latent_hist, dim=0)\n",
        "  return all_latents\n",
        "\n",
        "def prompt_to_img(prompts, height=512, width=512, num_inference_steps=50,\n",
        "                  guidance_scale=7.5, latents=None, return_all_latents=False,\n",
        "                  batch_size=2):\n",
        "  if isinstance(prompts, str):\n",
        "    prompts = [prompts]\n",
        "\n",
        "  # Prompts -> text embeds\n",
        "  text_embeds = get_text_embeds(prompts)\n",
        "\n",
        "  # Text embeds -> img latents\n",
        "  latents = produce_latents(\n",
        "      text_embeds, height=height, width=width, latents=latents,\n",
        "      num_inference_steps=num_inference_steps, guidance_scale=guidance_scale,\n",
        "      return_all_latents=return_all_latents)\n",
        "\n",
        "  # Img latents -> imgs\n",
        "  all_imgs = []\n",
        "  for i in tqdm(range(0, len(latents), batch_size)):\n",
        "    imgs = decode_img_latents(latents[i:i+batch_size])\n",
        "    all_imgs.extend(imgs)\n",
        "\n",
        "  return all_imgs"
      ],
      "metadata": {
        "id": "K52c_bG6SnbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Starry night with a violet sky digital art'\n",
        "video_frames = prompt_to_img(\n",
        "    prompt, num_inference_steps=40, return_all_latents=True)"
      ],
      "metadata": {
        "id": "KjZrF39mTShO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgs_to_video(imgs, video_name='video.mp4', fps=15):\n",
        "  # Source: https://stackoverflow.com/questions/52414148/turn-pil-images-into-video-on-linux\n",
        "  video_dims = (imgs[0].width, imgs[0].height)\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "  video = cv2.VideoWriter(video_name, fourcc, fps, video_dims)\n",
        "  for img in imgs:\n",
        "    tmp_img = img.copy()\n",
        "    video.write(cv2.cvtColor(np.array(tmp_img), cv2.COLOR_RGB2BGR))\n",
        "  video.release()\n",
        "\n",
        "def display_video(file_path, width=512):\n",
        "  compressed_vid_path = 'comp_' + file_path\n",
        "  if os.path.exists(compressed_vid_path):\n",
        "    os.remove(compressed_vid_path)\n",
        "  os.system(f'ffmpeg -i {file_path} -vcodec libx264 {compressed_vid_path}')\n",
        "\n",
        "  mp4 = open(compressed_vid_path, 'rb').read()\n",
        "  data_url = 'data:simul2/mp4;base64,' + b64encode(mp4).decode()\n",
        "  return HTML(\"\"\"\n",
        "    <video width={} controls>\n",
        "          <source src=\"{}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\".format(width, data_url))"
      ],
      "metadata": {
        "id": "bSIi5u_FTj-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vid_name = prompt.replace(' ', '_') + '.mp4'\n",
        "imgs_to_video(video_frames, vid_name)\n",
        "display_video(vid_name)"
      ],
      "metadata": {
        "id": "DxlIqGfATvvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similar Img"
      ],
      "metadata": {
        "id": "eQuA_IcwUBID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '\"A cat sitting on a grassy field\"'\n",
        "latents = torch.randn((1, unet.in_channels, 512 // 8, 512 // 8))\n",
        "img = prompt_to_img(prompt, num_inference_steps=20, latents=latents)[0]\n",
        "img"
      ],
      "metadata": {
        "id": "NGa9BlnVUBkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "46PXbZfLUiyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_latents(latents, scale=0.1):\n",
        "  noise = torch.randn_like(latents)\n",
        "  new_latents = (1 - scale) * latents + scale * noise\n",
        "  return (new_latents - new_latents.mean()) / new_latents.std()"
      ],
      "metadata": {
        "id": "JEU5s-dYUsaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_latents = perturb_latents(latents, 0.4)\n",
        "img = prompt_to_img(prompt, num_inference_steps=20, latents=new_latents)[0]\n",
        "img"
      ],
      "metadata": {
        "id": "pFgvbagcUt5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Img-to-Img"
      ],
      "metadata": {
        "id": "4RnIePDcVDgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = LMSDiscreteScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012,\n",
        "    beta_schedule='scaled_linear', num_train_timesteps=1000)"
      ],
      "metadata": {
        "id": "hNq8WZsBYKDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'squid'\n",
        "img = prompt_to_img(prompt, num_inference_steps=30)[0]\n",
        "img"
      ],
      "metadata": {
        "id": "CFQUCe9rVDpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_img_latents(imgs):\n",
        "  if not isinstance(imgs, list):\n",
        "    imgs = [imgs]\n",
        "\n",
        "  img_arr = np.stack([np.array(img) for img in imgs], axis=0)\n",
        "  img_arr = img_arr / 255.0\n",
        "  img_arr = torch.from_numpy(img_arr).float().permute(0, 3, 1, 2)\n",
        "  img_arr = 2 * (img_arr - 0.5)\n",
        "\n",
        "  latent_dists = vae.encode(img_arr.to(device))\n",
        "  latent_samples = latent_dists.sample()\n",
        "  latent_samples *= 0.18215\n",
        "\n",
        "  return latent_samples"
      ],
      "metadata": {
        "id": "F4NdNyhmVSj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_latents = encode_img_latents([img])\n",
        "# dec_img = decode_img_latents(img_latents)[0]\n",
        "# dec_img"
      ],
      "metadata": {
        "id": "tlwbHH7qVcx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New scheduler for img-to-img\n",
        "scheduler = DDIMScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012,\n",
        "    beta_schedule='scaled_linear', num_train_timesteps=1000)"
      ],
      "metadata": {
        "id": "kPcsENQmW_jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_latents(text_embeddings, height=512, width=512,\n",
        "                    num_inference_steps=50, guidance_scale=7.5, latents=None,\n",
        "                    return_all_latents=False, start_step=10):\n",
        "  if latents is None:\n",
        "    latents = torch.randn((text_embeddings.shape[0] // 2, unet.in_channels, \\\n",
        "                           height // 8, width // 8))\n",
        "  latents = latents.to(device)\n",
        "\n",
        "  scheduler.set_timesteps(num_inference_steps)\n",
        "  if start_step > 0:\n",
        "    start_timestep = scheduler.timesteps[start_step]\n",
        "    start_timesteps = start_timestep.repeat(latents.shape[0]).long()\n",
        "\n",
        "    noise = torch.randn_like(latents)\n",
        "    latents = scheduler.add_noise(latents, noise, start_timesteps)\n",
        "\n",
        "  latent_hist = [latents]\n",
        "  with autocast('cuda'):\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps[start_step:])):\n",
        "      # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "      latent_model_input = torch.cat([latents] * 2)\n",
        "\n",
        "      # predict the noise residual\n",
        "      with torch.no_grad():\n",
        "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)['sample']\n",
        "\n",
        "      # perform guidance\n",
        "      noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "      noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "      # compute the previous noisy sample x_t -> x_t-1\n",
        "      latents = scheduler.step(noise_pred, t, latents)['prev_sample']\n",
        "      latent_hist.append(latents)\n",
        "\n",
        "  if not return_all_latents:\n",
        "    return latents\n",
        "\n",
        "  all_latents = torch.cat(latent_hist, dim=0)\n",
        "  return all_latents\n",
        "\n",
        "def prompt_to_img(prompts, height=512, width=512, num_inference_steps=50,\n",
        "                  guidance_scale=7.5, latents=None, return_all_latents=False,\n",
        "                  batch_size=2, start_step=0):\n",
        "  if isinstance(prompts, str):\n",
        "    prompts = [prompts]\n",
        "\n",
        "  # Prompts -> text embeds\n",
        "  text_embeds = get_text_embeds(prompts)\n",
        "\n",
        "  # Text embeds -> img latents\n",
        "  latents = produce_latents(\n",
        "      text_embeds, height=height, width=width, latents=latents,\n",
        "      num_inference_steps=num_inference_steps, guidance_scale=guidance_scale,\n",
        "      return_all_latents=return_all_latents, start_step=start_step)\n",
        "\n",
        "  # Img latents -> imgs\n",
        "  all_imgs = []\n",
        "  for i in tqdm(range(0, len(latents), batch_size)):\n",
        "    imgs = decode_img_latents(latents[i:i+batch_size])\n",
        "    all_imgs.extend(imgs)\n",
        "\n",
        "  return all_imgs"
      ],
      "metadata": {
        "id": "redAdOaBV2Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Squidward'\n",
        "img = prompt_to_img(prompt, num_inference_steps=30, latents=img_latents,\n",
        "                    start_step=20)[0]\n",
        "img"
      ],
      "metadata": {
        "id": "43uONiOEW4Pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}